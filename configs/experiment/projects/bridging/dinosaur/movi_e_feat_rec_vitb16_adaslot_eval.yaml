# @package _global_
# ViT feature reconstruction on MOVI-E.
defaults:
  - /conditioning/random@models.conditioning
  - /experiment/projects/bridging/dinosaur/_base_feature_recon_gumbel
  - /neural_networks/mlp@models.object_decoder.decoder
  - /dataset: movi_e_image
  - /experiment/projects/bridging/dinosaur/_preprocessing_movi_dino_feature_recon
  - /experiment/projects/bridging/dinosaur/_metrics_clevr_patch
  - /metrics/tensor_statistic@evaluation_metrics.hard_keep_decision
  - /metrics/tensor_statistic@evaluation_metrics.slots_keep_prob
  - /metrics/ami_metric@evaluation_metrics.ami
  - /metrics/nmi_metric@evaluation_metrics.nmi
  - /metrics/purity_metric@evaluation_metrics.purity
  - /metrics/precision_metric@evaluation_metrics.precision
  - /metrics/recall_metric@evaluation_metrics.recall
  - /metrics/f1_metric@evaluation_metrics.f1
  - /metrics/mask_corloc_metric@evaluation_metrics.instance_mask_corloc
  - _self_

# The following parameters assume training on 8 GPUs, leading to an effective batch size of 64.
trainer:
  gpus: 8
  max_steps: 500000
  max_epochs: null
  strategy: ddp

dataset:
  num_workers: 4
  batch_size: 8

models:
  _target_: ocl.models.image_grouping_adaslot.GroupingImgGumbel
  conditioning:
    n_slots: 24
    object_dim: 128

  feature_extractor:
    model_name: vit_base_patch16_224_dino
    pretrained: true

  perceptual_grouping:
    input_dim: 768
    low_bound: 0

  object_decoder:
    _target_: ocl.decoding.PatchDecoderGumbelV1
    num_patches: 196
    decoder:
      features: [1024, 1024, 1024]
    left_mask_path: None
    mask_type: mask_normalized

  masks_as_image:
    _target_: ocl.utils.resizing.Resize
    input_path: object_decoder.masks
    size: 128
    resize_mode: bilinear
    patch_mode: true

losses:
  sparse_penalty:
    _target_: ocl.losses.SparsePenalty
    linear_weight: 0.1
    quadratic_weight: 0.0
    quadratic_bias: 0.5
    input_path: hard_keep_decision

evaluation_metrics:
  hard_keep_decision:
    path: hard_keep_decision
    reduction: sum

  slots_keep_prob:
    path: slots_keep_prob
    reduction: mean

  ami:
    prediction_path: masks_as_image
    target_path: input.mask
    foreground: true
    convert_target_one_hot: false
    ignore_overlaps: false

  nmi:
    prediction_path: masks_as_image
    target_path: input.mask
    foreground: true
    convert_target_one_hot: false
    ignore_overlaps: false
  
  purity:
    prediction_path: masks_as_image
    target_path: input.mask
    foreground: true
    convert_target_one_hot: false
    ignore_overlaps: false
  
  precision:
    prediction_path: masks_as_image
    target_path: input.mask
    foreground: true
    convert_target_one_hot: false
    ignore_overlaps: false
  
  recall:
    prediction_path: masks_as_image
    target_path: input.mask
    foreground: true
    convert_target_one_hot: false
    ignore_overlaps: false
  
  f1:
    prediction_path: masks_as_image
    target_path: input.mask
    foreground: true
    convert_target_one_hot: false
    ignore_overlaps: false

  instance_mask_corloc:
    prediction_path: masks_as_image
    target_path: input.mask
    use_threshold: False
    ignore_background: True
    ignore_overlaps: False
    
plugins:
  02_sample_frames:
    n_frames_per_video: 24
